{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timings here are for a machine with a K80 (specifically an Azure NC6). Running with a CPU only machine is going to quite a bit slower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /vol/bitbucket/hrs13/dnsgpfiles/data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /vol/bitbucket/hrs13/dnsgpfiles/data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /vol/bitbucket/hrs13/dnsgpfiles/data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /vol/bitbucket/hrs13/dnsgpfiles/data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../../DNSGP/GPflow')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from GPflow.likelihoods import MultiClass\n",
    "from GPflow.kernels import RBF, White, Linear, Matern32, Matern52\n",
    "from GPflow.svgp import SVGP\n",
    "from GPflow.gpr import GPR\n",
    "\n",
    "from GPflow.param import AutoFlow\n",
    "\n",
    "from scipy.stats import mode\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "from get_data import get_mnist_data\n",
    "from dgp import DGP\n",
    "\n",
    "import time\n",
    "\n",
    "X, Y, Xs, Ys = get_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 100 inducing points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = 100\n",
    "Z = kmeans2(X, M, minit='points')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Slightly annoyingly,  `AutoFlow` takes `Ynew` as a `float_type` in `predict_density`, but for the mutliclass likelihood the input is `tf.int32` (also the number of dimensions are different). We defined both versions in out `DGP` class, but as a workaround for `SVGP` we just override the behaviour:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiClassSVPG(SVGP):\n",
    "    @AutoFlow((tf.float64, [None, None]), (tf.int32, [None,]))\n",
    "    def predict_density(self, Xnew, Ynew):\n",
    "        pred_f_mean, pred_f_var = self.build_predict(Xnew)\n",
    "        return self.likelihood.predict_density(pred_f_mean, pred_f_var, Ynew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare three models: an ordinary sparse GP and DGPs with 2 and 3 layers. \n",
    "\n",
    "We'll use a batch size of 10000 for all models (it works fine with smaller batch sizes, but this is what we did in the paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_sgp = MultiClassSVPG(X, Y, RBF(784, lengthscales=2, variance=2), \n",
    "             MultiClass(10), Z, \n",
    "             num_latent=10, minibatch_size=1000)\n",
    "\n",
    "def make_dgp(L):\n",
    "    kernels = [RBF(784, lengthscales=2., variance=2.)]\n",
    "    for l in range(L-1):\n",
    "        kernels.append(RBF(30, lengthscales=2., variance=2.))\n",
    "    model = DGP(X, Y, Z, kernels, MultiClass(10), \n",
    "                num_samples=1,\n",
    "                minibatch_size=1000,\n",
    "                num_latent_Y=10)\n",
    "\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.q_sqrt = layer.q_sqrt.value * 1e-5 \n",
    "    \n",
    "    return model\n",
    "\n",
    "m_dgp2 = make_dgp(2)\n",
    "m_dgp3 = make_dgp(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train for 10000 iterations, printing every 1000 to see how convergence is doing. We'll predict also at the training data to see what's going (we don't use a validation set). \n",
    "\n",
    "For the SGP model we'll calcuate accuracy by simply taking the max mean prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assess_model_sgp(model, X_batch, Y_batch):\n",
    "    m, v = model.predict_y(X_batch)\n",
    "    l = model.predict_density(X_batch, Y_batch)\n",
    "    a = (np.argmax(m, 1)==Y_batch)\n",
    "    return l, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DGP models we have stochastic predictions. We need a single prediction for each datum, so to do this we take $S$ samples for the one-hot predictions ($(S, N, 10)$ matrices for mean and var), then we take the max over the class means (to give a $(S, N)$ matrix), and finally we take the modal class over the samples (to give a vector of length $N$):\n",
    "\n",
    "We'll use 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = 100\n",
    "def assess_model_dgp(model, X_batch, Y_batch):\n",
    "    m, v = model.predict_y(X_batch, S)\n",
    "    l = model.predict_density_multiclass(X_batch, Y_batch, S)\n",
    "    a = (mode(np.argmax(m, 2), 0)[0].flatten()==Y_batch)\n",
    "    return l, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need batch predictions (we might run out of memory as `Xs` is 10,000 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_assess(model, assess_model, X, Y):\n",
    "    n_batches = int(len(X)/100)\n",
    "    lik, acc = [], []\n",
    "    for X_batch, Y_batch in zip(np.split(X, n_batches), np.split(Y, n_batches)):\n",
    "        l, a = assess_model(model, X_batch, Y_batch)\n",
    "        lik.append(l)\n",
    "        acc.append(a)\n",
    "    lik = np.concatenate(lik, 0)\n",
    "    acc = np.array(np.concatenate(acc, 0), dtype=float)\n",
    "    return np.average(lik), np.average(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, we'll use the following callback to log what's going on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CB(object):\n",
    "    def __init__(self, model, assess_model):\n",
    "        self.model = model\n",
    "        self.assess_model = assess_model\n",
    "        self.i = 0\n",
    "        self.t = time.time()\n",
    "        self.train_time = 0\n",
    "        self.ob = []\n",
    "        self.train_lik = []\n",
    "        self.train_acc = []\n",
    "    def cb(self, x):\n",
    "        self.i += 1\n",
    "        if self.i % 1000 == 0:\n",
    "            # time how long we've be training \n",
    "            self.train_time += time.time() - self.t\n",
    "            self.t = time.time()\n",
    "            \n",
    "            # assess the model on the training data\n",
    "            self.model.set_state(x)\n",
    "            lik, acc = batch_assess(self.model, self.assess_model, X, Y)\n",
    "            self.train_lik.append(lik)\n",
    "            self.train_acc.append(acc)\n",
    "            \n",
    "            # calculate the objective, averaged over S samples \n",
    "            ob = 0\n",
    "            for _ in range(S):\n",
    "                ob += self.model.compute_log_likelihood()/float(S)\n",
    "            self.ob.append(ob)\n",
    "            \n",
    "            st = 'it: {}, ob: {:.1f}, train lik: {:.4f}, train acc {:.4f}'\n",
    "            print st.format(self.i, ob, lik, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to go\n",
    "\n",
    "The sparse GP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 1000, ob: -38777.3, train lik: -0.1424, train acc 0.9634\n",
      "it: 2000, ob: -34423.9, train lik: -0.1268, train acc 0.9691\n",
      "it: 3000, ob: -32992.6, train lik: -0.1179, train acc 0.9717\n",
      "it: 4000, ob: -32617.8, train lik: -0.1178, train acc 0.9725\n",
      "it: 5000, ob: -32131.9, train lik: -0.1129, train acc 0.9738\n",
      "it: 6000, ob: -31842.0, train lik: -0.1150, train acc 0.9740\n",
      "it: 7000, ob: -31593.7, train lik: -0.1127, train acc 0.9735\n",
      "it: 8000, ob: -32258.5, train lik: -0.1106, train acc 0.9746\n",
      "it: 9000, ob: -31711.1, train lik: -0.1091, train acc 0.9751\n",
      "it: 10000, ob: -31647.1, train lik: -0.1093, train acc 0.9748\n",
      "it: 11000, ob: -31358.6, train lik: -0.1079, train acc 0.9750\n",
      "it: 12000, ob: -31733.9, train lik: -0.1066, train acc 0.9753\n",
      "it: 13000, ob: -31090.2, train lik: -0.1066, train acc 0.9754\n",
      "it: 14000, ob: -31161.8, train lik: -0.1063, train acc 0.9753\n",
      "it: 15000, ob: -31063.1, train lik: -0.1033, train acc 0.9759\n",
      "it: 16000, ob: -30912.5, train lik: -0.1050, train acc 0.9758\n",
      "it: 17000, ob: -30830.0, train lik: -0.1037, train acc 0.9756\n",
      "it: 18000, ob: -31264.9, train lik: -0.1027, train acc 0.9756\n",
      "it: 19000, ob: -31020.5, train lik: -0.1029, train acc 0.9756\n",
      "it: 20000, ob: -31486.2, train lik: -0.1038, train acc 0.9754\n",
      "sgp total train time 2429.4402\n",
      "spg test lik: -0.1111, test acc 0.9692\n"
     ]
    }
   ],
   "source": [
    "cb_sgp = CB(m_sgp, assess_model_sgp)\n",
    "m_sgp.optimize(tf.train.AdamOptimizer(0.01), maxiter=20000, callback=cb_sgp.cb)\n",
    "print 'sgp total train time {:.4f}'.format(cb_sgp.train_time)\n",
    "l, a = batch_assess(m_sgp, assess_model_sgp, Xs, Ys)\n",
    "print 'spg test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it scores a respectible 97%, but nothing spectacular. Using more inducing points improves things, but at the expense of very slow computation (500 inducing points takes about a day)\n",
    "\n",
    "Here is the two layer DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 1000, ob: -37047.9, train lik: -0.1161, train acc 0.9708\n",
      "it: 2000, ob: -31068.3, train lik: -0.0927, train acc 0.9771\n",
      "it: 3000, ob: -27779.5, train lik: -0.0836, train acc 0.9802\n",
      "it: 4000, ob: -25298.2, train lik: -0.0790, train acc 0.9815\n",
      "it: 5000, ob: -25096.4, train lik: -0.0774, train acc 0.9817\n",
      "it: 6000, ob: -23652.5, train lik: -0.0742, train acc 0.9828\n",
      "it: 7000, ob: -22826.9, train lik: -0.0730, train acc 0.9831\n",
      "it: 8000, ob: -22949.9, train lik: -0.0699, train acc 0.9838\n",
      "it: 9000, ob: -22131.3, train lik: -0.0696, train acc 0.9844\n",
      "it: 10000, ob: -22001.0, train lik: -0.0687, train acc 0.9845\n",
      "it: 11000, ob: -21834.3, train lik: -0.0681, train acc 0.9849\n",
      "it: 12000, ob: -22019.1, train lik: -0.0669, train acc 0.9850\n",
      "it: 13000, ob: -21296.0, train lik: -0.0662, train acc 0.9854\n",
      "it: 14000, ob: -21743.0, train lik: -0.0651, train acc 0.9851\n",
      "it: 15000, ob: -21310.5, train lik: -0.0642, train acc 0.9856\n",
      "it: 16000, ob: -21324.8, train lik: -0.0645, train acc 0.9855\n",
      "it: 17000, ob: -21313.9, train lik: -0.0663, train acc 0.9856\n",
      "it: 18000, ob: -21392.4, train lik: -0.0633, train acc 0.9859\n",
      "it: 19000, ob: -21441.5, train lik: -0.0651, train acc 0.9855\n",
      "it: 20000, ob: -21423.8, train lik: -0.0647, train acc 0.9856\n",
      "dgp2 total train time 28498.8396\n",
      "dgp2 test lik: -0.0761, test acc 0.9791\n"
     ]
    }
   ],
   "source": [
    "cb_dgp2 = CB(m_dgp2, assess_model_dgp)\n",
    "m_dgp2.optimize(tf.train.AdamOptimizer(0.01), maxiter=20000, callback=cb_dgp2.cb)\n",
    "print 'dgp2 total train time {:.4f}'.format(cb_dgp2.train_time)\n",
    "l, a = batch_assess(m_dgp2, assess_model_dgp, Xs, Ys)\n",
    "print 'dgp2 test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-02c29d3e9515>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-02c29d3e9515>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    And the three layer\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "And the three layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb_dgp3 = CB(m_dgp3, assess_model_dgp)\n",
    "m_dgp3.optimize(tf.train.AdamOptimizer(0.01), maxiter=20000, callback=cb_dgp3.cb)\n",
    "print 'dgp3 total train time {:.4f}'.format(cb_dgp3.train_time)\n",
    "l, a = batch_assess(m_dgp3, assess_model_dgp, Xs, Ys)\n",
    "print 'dgp3 test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 layer DGP wins! \n",
    "\n",
    "We can see how they've done over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cb_sgp.train_acc, label='sgp')\n",
    "plt.plot(cb_dgp2.train_acc, label='dgp2')\n",
    "plt.plot(cb_dgp3.train_acc, label='dgp3')\n",
    "plt.title('train accuray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
