{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timings here are for a machine with a K80 (specifically an Azure NC6). Running with a CPU only machine is going to quite a bit slower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../../DNSGP/GPflow/')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from GPflow.likelihoods import MultiClass\n",
    "from GPflow.kernels import RBF, White, Linear, Matern32, Matern52\n",
    "from GPflow.svgp import SVGP\n",
    "from GPflow.gpr import GPR\n",
    "\n",
    "from GPflow.param import AutoFlow\n",
    "\n",
    "from scipy.stats import mode\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "from get_data import get_mnist_data\n",
    "from dgp import DGP\n",
    "\n",
    "import time\n",
    "\n",
    "X, Y, Xs, Ys = get_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 100 inducing points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 100\n",
    "Z = kmeans2(X, M, minit='points')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "print Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly annoyingly,  `AutoFlow` takes `Ynew` as a `float_type` in `predict_density`, but for the mutliclass likelihood the input is `tf.int32` (also the number of dimensions are different). We defined both versions in out `DGP` class, but as a workaround for `SVGP` we just override the behaviour:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiClassSVPG(SVGP):\n",
    "    @AutoFlow((tf.float64, [None, None]), (tf.int32, [None,]))\n",
    "    def predict_density(self, Xnew, Ynew):\n",
    "        pred_f_mean, pred_f_var = self.build_predict(Xnew)\n",
    "        return self.likelihood.predict_density(pred_f_mean, pred_f_var, Ynew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare three models: an ordinary sparse GP and DGPs with 2 and 3 layers. \n",
    "\n",
    "We'll use a batch size of 10000 for all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_sgp = MultiClassSVPG(X, Y, RBF(784, lengthscales=2, variance=2), \n",
    "             MultiClass(10), Z, \n",
    "             num_latent=10, minibatch_size=1000, whiten=True)\n",
    "\n",
    "def make_dgp(L):\n",
    "    kernels = [RBF(784, lengthscales=2., variance=2.)]\n",
    "    for l in range(L-1):\n",
    "        kernels.append(RBF(30, lengthscales=2., variance=2.))\n",
    "    model = DGP(X, Y, Z, kernels, MultiClass(10), \n",
    "                num_samples=1,\n",
    "                minibatch_size=1000,\n",
    "                num_latent_Y=10)\n",
    "\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.q_sqrt = layer.q_sqrt.value * 1e-5 \n",
    "    \n",
    "    return model\n",
    "\n",
    "m_dgp2 = make_dgp(2)\n",
    "m_dgp3 = make_dgp(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SGP model we'll calcuate accuracy by simply taking the max mean prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assess_model_sgp(model, X_batch, Y_batch):\n",
    "    m, v = model.predict_y(X_batch)\n",
    "    l = model.predict_density(X_batch, Y_batch)\n",
    "    a = (np.argmax(m, 1)==Y_batch)\n",
    "    return l, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DGP models we have stochastic predictions. We need a single prediction for each datum, so to do this we take $S$ samples for the one-hot predictions ($(S, N, 10)$ matrices for mean and var), then we take the max over the class means (to give a $(S, N)$ matrix), and finally we take the modal class over the samples (to give a vector of length $N$):\n",
    "\n",
    "We'll use 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = 1000\n",
    "def assess_model_dgp(model, X_batch, Y_batch):\n",
    "    m, v = model.predict_y(X_batch, S)\n",
    "    l = model.predict_density_multiclass(X_batch, Y_batch, S)\n",
    "    a = (mode(np.argmax(m, 2), 0)[0].flatten()==Y_batch)\n",
    "    return l, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need batch predictions (we might run out of memory as `Xs` is 10,000 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_assess(model, assess_model, X, Y):\n",
    "    n_batches = int(len(X)/100)\n",
    "    lik, acc = [], []\n",
    "    for X_batch, Y_batch in zip(np.split(X, n_batches), np.split(Y, n_batches)):\n",
    "        l, a = assess_model(model, X_batch, Y_batch)\n",
    "        lik.append(l)\n",
    "        acc.append(a)\n",
    "    lik = np.concatenate(lik, 0)\n",
    "    acc = np.array(np.concatenate(acc, 0), dtype=float)\n",
    "    return np.average(lik), np.average(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll use the following callback to log what's going on \n",
    "\n",
    "We'll train for 10000 iterations, printing every 1000 to see how convergence is doing. We'll predict also at the training data to see what's going (we don't use a validation set). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CB(object):\n",
    "    def __init__(self, model, assess_model):\n",
    "        self.model = model\n",
    "        self.assess_model = assess_model\n",
    "        self.i = 0\n",
    "        self.t = time.time()\n",
    "        self.train_time = 0\n",
    "        self.ob = []\n",
    "        self.train_lik = []\n",
    "        self.train_acc = []\n",
    "    def cb(self, x):\n",
    "        self.i += 1\n",
    "        if self.i % 1 == 0:\n",
    "            # time how long we've be training \n",
    "            self.train_time += time.time() - self.t\n",
    "            self.t = time.time()\n",
    "            \n",
    "            # assess the model on the training data\n",
    "            self.model.set_state(x)\n",
    "            lik, acc = batch_assess(self.model, self.assess_model, X, Y)\n",
    "            self.train_lik.append(lik)\n",
    "            self.train_acc.append(acc)\n",
    "            \n",
    "            # calculate the objective, averaged over S samples \n",
    "            ob = 0\n",
    "            for _ in range(1):\n",
    "                ob += self.model.compute_log_likelihood()/float(1)\n",
    "            self.ob.append(ob)\n",
    "            \n",
    "            st = 'it: {}, ob: {:.1f}, train lik: {:.4f}, train acc {:.4f}'\n",
    "            print st.format(self.i, ob, lik, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to go\n",
    "\n",
    "The sparse GP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 1, ob: -486895.3, train lik: -2.2299, train acc 0.8340\n",
      "it: 2, ob: -485875.8, train lik: -2.2204, train acc 0.8342\n",
      "it: 3, ob: -485273.1, train lik: -2.2106, train acc 0.8349\n",
      "it: 4, ob: -485001.6, train lik: -2.2008, train acc 0.8351\n",
      "it: 5, ob: -483369.6, train lik: -2.1907, train acc 0.8353\n",
      "it: 6, ob: -482753.4, train lik: -2.1805, train acc 0.8358\n",
      "it: 7, ob: -480550.8, train lik: -2.1703, train acc 0.8370\n",
      "it: 8, ob: -480483.6, train lik: -2.1599, train acc 0.8374\n",
      "it: 9, ob: -479240.3, train lik: -2.1494, train acc 0.8380\n",
      "it: 10, ob: -477229.9, train lik: -2.1388, train acc 0.8387\n",
      "sgp total train time 173.0981\n",
      "spg test lik: -2.1352, test acc 0.8445\n"
     ]
    }
   ],
   "source": [
    "cb_sgp = CB(m_sgp, assess_model_sgp)\n",
    "m_sgp.optimize(tf.train.AdamOptimizer(0.01), maxiter=10, callback=cb_sgp.cb)\n",
    "print 'sgp total train time {:.4f}'.format(cb_sgp.train_time)\n",
    "l, a = batch_assess(m_sgp, assess_model_sgp, Xs, Ys)\n",
    "print 'spg test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from GPflow.gpr import GPR\n",
    "X = np.linspace(0, 1, 100)[:, None]\n",
    "Y = np.sin(10*X)\n",
    "Xs = np.random.uniform(0, 1, 100)[:, None]\n",
    "Ys = np.sin(10*X)\n",
    "\n",
    "model = GPR(X, Y, RBF(1))\n",
    "m, v = model.predict_y(Xs)\n",
    "print  np.average((m - Xs)**2)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-491708.145615\n",
      "34.8770301342\n"
     ]
    }
   ],
   "source": [
    "from GPflow.kernels import White, RBF\n",
    "from GPflow.likelihoods import Gaussian\n",
    "from GPflow.sgpr import SGPR\n",
    "from GPflow.gpr import GPR\n",
    "\n",
    "svgp = SVGP(X, np.array(Y[:, None], dtype=float), RBF(784, lengthscales=20, variance=2.), Gaussian(), Z, num_latent=10)\n",
    "svgp = SVGP(X, Y, RBF(784, lengthscales=20, variance=2.), MultiClass(10), Z, num_latent=10)\n",
    "# svgp = SVGP(X[:10], np.array(Y[:10, None], dtype=float), White(784), Gaussian(), X[:10])#, num_latent=10)\n",
    "# svgp = GPR(X[:100], np.array(Y[:100, None], dtype=float), RBF(784))#, num_latent=10)\n",
    "# svgp = SGPR(X[:1000], np.array(Y[:1000, None], dtype=float), RBF(784), X[:100])#, num_latent=10)\n",
    "t = time.time()\n",
    "print svgp.compute_log_likelihood()\n",
    "\n",
    "\n",
    "svgp.optimize(maxiter=2)\n",
    "print time.time() - t\n",
    "# -1506.89385332\n",
    "# print Y[:10, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-334113.725606\n",
      "0.505330085754\n",
      "[[-1.43891014 -3.46352971  3.98614993 -0.7374889   2.92201216 -9.4036516\n",
      "   9.11916085  0.54827626 -1.24523868 -0.28678017]\n",
      " [-0.67047457  1.99230342  5.58693348  1.35280026 -0.65118404 -9.5814999\n",
      "   4.00512604 -0.09307582  0.42266724 -2.36359611]]\n"
     ]
    }
   ],
   "source": [
    "print svgp.compute_log_likelihood()\n",
    "t = time.time()\n",
    "m, v = svgp.predict_f(Xs[:2])\n",
    "print time.time() - t\n",
    "print m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kern.\u001b[1mlengthscales\u001b[0m transform:+ve prior:None\n",
      "[ 16.38015575]\n",
      "kern.\u001b[1mvariance\u001b[0m transform:+ve prior:None\n",
      "[ 2.00002661]\n",
      "(100, 10)\n",
      "(100, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "print svgp.kern\n",
    "print svgp.q_mu.value.shape\n",
    "print svgp.q_sqrt.value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using more inducing points improves things, but at the expense of very slow computation (500 inducing points takes about a day)\n",
    "\n",
    "The two layer DGP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_dgp2 = CB(m_dgp2, assess_model_dgp)\n",
    "m_dgp2.optimize(tf.train.AdamOptimizer(0.01), maxiter=20000, callback=cb_dgp2.cb)\n",
    "print 'dgp2 total train time {:.4f}'.format(cb_dgp2.train_time)\n",
    "l, a = batch_assess(m_dgp2, assess_model_dgp, Xs, Ys)\n",
    "print 'dgp2 test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "And the three layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_dgp3 = CB(m_dgp3, assess_model_dgp)\n",
    "m_dgp3.optimize(tf.train.AdamOptimizer(0.01), maxiter=20000, callback=cb_dgp3.cb)\n",
    "print 'dgp3 total train time {:.4f}'.format(cb_dgp3.train_time)\n",
    "l, a = batch_assess(m_dgp3, assess_model_dgp, Xs, Ys)\n",
    "print 'dgp3 test lik: {:.4f}, test acc {:.4f}'.format(l, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 layer DGP wins! \n",
    "\n",
    "We can see how they've done over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(cb_sgp.train_acc, label='sgp')\n",
    "plt.plot(cb_dgp2.train_acc, label='dgp2')\n",
    "plt.plot(cb_dgp3.train_acc, label='dgp3')\n",
    "plt.title('train accuray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
